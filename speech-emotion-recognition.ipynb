{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-11T16:16:31.0901Z","iopub.execute_input":"2022-05-11T16:16:31.090556Z","iopub.status.idle":"2022-05-11T16:16:31.094064Z","shell.execute_reply.started":"2022-05-11T16:16:31.090523Z","shell.execute_reply":"2022-05-11T16:16:31.093268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Module","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os # File Manipulation\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Audio Libraries\nimport librosa\nimport librosa.display\n\nfrom IPython.display import Audio # Import Audio\nimport warnings\nwarnings.filterwarnings('ignore') # Will ignore all the warnings","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:31.16734Z","iopub.execute_input":"2022-05-11T16:16:31.167765Z","iopub.status.idle":"2022-05-11T16:16:34.270127Z","shell.execute_reply.started":"2022-05-11T16:16:31.167734Z","shell.execute_reply":"2022-05-11T16:16:34.269026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load The Dataset","metadata":{}},{"cell_type":"code","source":"paths = []\nlabels = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        labels.append(label.lower())\nprint('Dataset is loaded')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:34.271898Z","iopub.execute_input":"2022-05-11T16:16:34.272207Z","iopub.status.idle":"2022-05-11T16:16:35.795645Z","shell.execute_reply.started":"2022-05-11T16:16:34.272144Z","shell.execute_reply":"2022-05-11T16:16:35.794772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:35.79923Z","iopub.execute_input":"2022-05-11T16:16:35.800366Z","iopub.status.idle":"2022-05-11T16:16:35.809671Z","shell.execute_reply.started":"2022-05-11T16:16:35.800308Z","shell.execute_reply":"2022-05-11T16:16:35.80876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:35.812417Z","iopub.execute_input":"2022-05-11T16:16:35.813042Z","iopub.status.idle":"2022-05-11T16:16:35.824634Z","shell.execute_reply.started":"2022-05-11T16:16:35.812994Z","shell.execute_reply":"2022-05-11T16:16:35.823477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['speech'] = paths\ndf['labels'] = labels\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:35.82643Z","iopub.execute_input":"2022-05-11T16:16:35.827587Z","iopub.status.idle":"2022-05-11T16:16:35.862035Z","shell.execute_reply.started":"2022-05-11T16:16:35.827535Z","shell.execute_reply":"2022-05-11T16:16:35.86102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:35.86365Z","iopub.execute_input":"2022-05-11T16:16:35.864599Z","iopub.status.idle":"2022-05-11T16:16:35.878063Z","shell.execute_reply.started":"2022-05-11T16:16:35.864548Z","shell.execute_reply":"2022-05-11T16:16:35.877267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.countplot(df['labels']) # Perform class balancing if the not balanced","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:35.880016Z","iopub.execute_input":"2022-05-11T16:16:35.880701Z","iopub.status.idle":"2022-05-11T16:16:36.205527Z","shell.execute_reply.started":"2022-05-11T16:16:35.880651Z","shell.execute_reply":"2022-05-11T16:16:36.204534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to visualize the audio waveform\ndef waveplot(data, sr, emotion):\n    plt.figure(figsize=(10,4))\n    plt.title(emotion, size=20)\n    librosa.display.waveshow(data, sr=sr)\n    plt.show()\n    \n# Function to visualize the audio spectogram\ndef spectogram(data, sr, emotion):\n    # Processing the data for spectogram visualization\n    x = librosa.stft(data)\n    xdb = librosa.amplitude_to_db(abs(x))\n    plt.figure(figsize=(10,4))\n    plt.title(emotion, size=20)\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:36.207185Z","iopub.execute_input":"2022-05-11T16:16:36.20786Z","iopub.status.idle":"2022-05-11T16:16:36.219293Z","shell.execute_reply.started":"2022-05-11T16:16:36.207806Z","shell.execute_reply":"2022-05-11T16:16:36.215882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:36.221117Z","iopub.execute_input":"2022-05-11T16:16:36.221479Z","iopub.status.idle":"2022-05-11T16:16:37.900075Z","shell.execute_reply.started":"2022-05-11T16:16:36.221439Z","shell.execute_reply":"2022-05-11T16:16:37.899127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'angry'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:37.903288Z","iopub.execute_input":"2022-05-11T16:16:37.903561Z","iopub.status.idle":"2022-05-11T16:16:40.029561Z","shell.execute_reply.started":"2022-05-11T16:16:37.903527Z","shell.execute_reply":"2022-05-11T16:16:40.028314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'disgust'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:40.031431Z","iopub.execute_input":"2022-05-11T16:16:40.031776Z","iopub.status.idle":"2022-05-11T16:16:40.897965Z","shell.execute_reply.started":"2022-05-11T16:16:40.031732Z","shell.execute_reply":"2022-05-11T16:16:40.896817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'neutral'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:40.899357Z","iopub.execute_input":"2022-05-11T16:16:40.899669Z","iopub.status.idle":"2022-05-11T16:16:41.748795Z","shell.execute_reply.started":"2022-05-11T16:16:40.899636Z","shell.execute_reply":"2022-05-11T16:16:41.747763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'sad'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:41.75048Z","iopub.execute_input":"2022-05-11T16:16:41.750784Z","iopub.status.idle":"2022-05-11T16:16:43.925707Z","shell.execute_reply.started":"2022-05-11T16:16:41.750745Z","shell.execute_reply":"2022-05-11T16:16:43.924811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'ps'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:43.926967Z","iopub.execute_input":"2022-05-11T16:16:43.927209Z","iopub.status.idle":"2022-05-11T16:16:44.761502Z","shell.execute_reply.started":"2022-05-11T16:16:43.92718Z","shell.execute_reply":"2022-05-11T16:16:44.760637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['labels'] == emotion])[0]\ndata, sampling_rate = librosa.load(path) # Loading the audio file\n\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\n\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:44.76261Z","iopub.execute_input":"2022-05-11T16:16:44.762829Z","iopub.status.idle":"2022-05-11T16:16:46.780713Z","shell.execute_reply.started":"2022-05-11T16:16:44.762801Z","shell.execute_reply":"2022-05-11T16:16:46.779662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"def extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0) # 40 is the number of features after which we get the mean\n    return mfcc","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:46.781996Z","iopub.execute_input":"2022-05-11T16:16:46.782236Z","iopub.status.idle":"2022-05-11T16:16:46.788769Z","shell.execute_reply.started":"2022-05-11T16:16:46.782208Z","shell.execute_reply":"2022-05-11T16:16:46.787634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_mfcc(df['speech'][0]) # Test for 1 file","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:46.790048Z","iopub.execute_input":"2022-05-11T16:16:46.790325Z","iopub.status.idle":"2022-05-11T16:16:46.953934Z","shell.execute_reply.started":"2022-05-11T16:16:46.790293Z","shell.execute_reply":"2022-05-11T16:16:46.952701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:46.955721Z","iopub.execute_input":"2022-05-11T16:16:46.956245Z","iopub.status.idle":"2022-05-11T16:26:23.570985Z","shell.execute_reply.started":"2022-05-11T16:16:46.956186Z","shell.execute_reply":"2022-05-11T16:26:23.569663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mfcc","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.577667Z","iopub.execute_input":"2022-05-11T16:26:23.578429Z","iopub.status.idle":"2022-05-11T16:26:23.598541Z","shell.execute_reply.started":"2022-05-11T16:26:23.578363Z","shell.execute_reply":"2022-05-11T16:26:23.597494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert list into 2-dimentional numpy array\nX = [x for x in X_mfcc]\nX = np.array(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.600575Z","iopub.execute_input":"2022-05-11T16:26:23.601208Z","iopub.status.idle":"2022-05-11T16:26:23.629316Z","shell.execute_reply.started":"2022-05-11T16:26:23.601137Z","shell.execute_reply":"2022-05-11T16:26:23.627993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input split and expand the dimension which is accepted by the LSTM Model\nx = np.expand_dims(X, -1)\nx.shape # We get the number of samples and features","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.636119Z","iopub.execute_input":"2022-05-11T16:26:23.640366Z","iopub.status.idle":"2022-05-11T16:26:23.648619Z","shell.execute_reply.started":"2022-05-11T16:26:23.64027Z","shell.execute_reply":"2022-05-11T16:26:23.647472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[1:]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.650394Z","iopub.execute_input":"2022-05-11T16:26:23.650843Z","iopub.status.idle":"2022-05-11T16:26:23.665521Z","shell.execute_reply.started":"2022-05-11T16:26:23.650797Z","shell.execute_reply":"2022-05-11T16:26:23.664361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the output column by converting to categorical columns\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['labels']])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.667088Z","iopub.execute_input":"2022-05-11T16:26:23.667538Z","iopub.status.idle":"2022-05-11T16:26:23.686752Z","shell.execute_reply.started":"2022-05-11T16:26:23.66749Z","shell.execute_reply":"2022-05-11T16:26:23.685205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[600:605]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T17:13:20.2673Z","iopub.execute_input":"2022-05-11T17:13:20.267617Z","iopub.status.idle":"2022-05-11T17:13:20.274246Z","shell.execute_reply.started":"2022-05-11T17:13:20.267582Z","shell.execute_reply":"2022-05-11T17:13:20.273388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[600:605]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T17:13:32.425205Z","iopub.execute_input":"2022-05-11T17:13:32.426193Z","iopub.status.idle":"2022-05-11T17:13:32.432353Z","shell.execute_reply.started":"2022-05-11T17:13:32.426112Z","shell.execute_reply":"2022-05-11T17:13:32.431724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y.toarray() # Sparse matrix (1 means corresponding output label is enabled)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.688214Z","iopub.execute_input":"2022-05-11T16:26:23.689231Z","iopub.status.idle":"2022-05-11T16:26:23.700155Z","shell.execute_reply.started":"2022-05-11T16:26:23.689175Z","shell.execute_reply":"2022-05-11T16:26:23.699404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape # Gives us the number of samples and number of categories","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.701509Z","iopub.execute_input":"2022-05-11T16:26:23.702229Z","iopub.status.idle":"2022-05-11T16:26:23.716524Z","shell.execute_reply.started":"2022-05-11T16:26:23.702176Z","shell.execute_reply":"2022-05-11T16:26:23.715745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We don't need to do test split and train split\nValuation split will be done in the LSTM model itself","metadata":{}},{"cell_type":"markdown","source":"## Create the LSTM Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\n\n# Adding different layers to our model\n# RNN loppback\n\nmodel = Sequential([\n    LSTM(256, return_sequences=False, input_shape=(40,1)),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:23.717842Z","iopub.execute_input":"2022-05-11T16:26:23.71829Z","iopub.status.idle":"2022-05-11T16:26:31.136361Z","shell.execute_reply.started":"2022-05-11T16:26:23.718238Z","shell.execute_reply":"2022-05-11T16:26:31.135335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:31.137786Z","iopub.execute_input":"2022-05-11T16:26:31.138104Z","iopub.status.idle":"2022-05-11T16:26:31.145796Z","shell.execute_reply.started":"2022-05-11T16:26:31.138057Z","shell.execute_reply":"2022-05-11T16:26:31.144826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"# X is the input, y is the output\nhistory = model.fit(\n    x,\n    y,\n    validation_split=0.2,\n    epochs=80,\n    batch_size=200,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:26:31.150838Z","iopub.execute_input":"2022-05-11T16:26:31.151524Z","iopub.status.idle":"2022-05-11T16:36:55.309775Z","shell.execute_reply.started":"2022-05-11T16:26:31.151469Z","shell.execute_reply":"2022-05-11T16:36:55.308929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the Results","metadata":{}},{"cell_type":"code","source":"epochs = list(range(100))\naccuracy = history.history['accuracy']\nvalidation_accuracy = history.history['val_accuracy']\n\nplt.plot(epochs, accuracy, label='train_accuracy')\nplt.plot(epochs, validation_accuracy, label='validation_accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:36:55.311397Z","iopub.execute_input":"2022-05-11T16:36:55.311799Z","iopub.status.idle":"2022-05-11T16:36:55.47757Z","shell.execute_reply.started":"2022-05-11T16:36:55.311767Z","shell.execute_reply":"2022-05-11T16:36:55.476914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n\nplt.plot(epochs, loss, label='train_loss')\nplt.plot(epochs, validation_loss, label='validation_loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:36:55.478788Z","iopub.execute_input":"2022-05-11T16:36:55.479647Z","iopub.status.idle":"2022-05-11T16:36:55.683436Z","shell.execute_reply.started":"2022-05-11T16:36:55.479595Z","shell.execute_reply":"2022-05-11T16:36:55.682503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/trained_models/ser.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:36:55.684601Z","iopub.execute_input":"2022-05-11T16:36:55.684826Z","iopub.status.idle":"2022-05-11T16:36:55.728854Z","shell.execute_reply.started":"2022-05-11T16:36:55.684788Z","shell.execute_reply":"2022-05-11T16:36:55.728231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# Convert the model\nconverter = tf.lite.TFLiteConverter.from_keras_model(model) # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.  \nwith open('/kaggle/working/trained_models/model300epochs.tflite', 'wb') as f:\n  f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T18:15:21.943069Z","iopub.execute_input":"2022-05-11T18:15:21.944177Z","iopub.status.idle":"2022-05-11T18:15:31.51772Z","shell.execute_reply.started":"2022-05-11T18:15:21.944069Z","shell.execute_reply":"2022-05-11T18:15:31.51626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ls = model.predict(['/kaggle/input/myvoice/angry.wav','/kaggle/input/myvoice/sad.wav','/kaggle/input/myvoice/happy.wav'])\n\n\ntest_aud = extract_mfcc('/kaggle/input/hellow/harshitsad.wav')\ntest_aud = np.array(test_aud)\ntest_aud=np.expand_dims(test_aud,-1)\n\ntest_aud=test_aud.reshape(1,-1,1)\n\ntest_aud.shape\n\nls = model.predict(test_aud)\nprint(ls)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T17:27:46.734109Z","iopub.execute_input":"2022-05-11T17:27:46.734438Z","iopub.status.idle":"2022-05-11T17:27:47.020037Z","shell.execute_reply.started":"2022-05-11T17:27:46.734406Z","shell.execute_reply":"2022-05-11T17:27:47.01722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2022-05-11T17:07:10.784809Z","iopub.execute_input":"2022-05-11T17:07:10.785128Z","iopub.status.idle":"2022-05-11T17:07:10.810383Z","shell.execute_reply.started":"2022-05-11T17:07:10.785094Z","shell.execute_reply":"2022-05-11T17:07:10.809631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}